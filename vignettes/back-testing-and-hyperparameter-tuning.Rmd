---
title: "Back Testing and Hyperparameter Tuning"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{back-testing-and-hyperparameter-tuning}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Most models automatically included in finnts, including all multivariate models, have various hyperparameters with values that need to be chosen before a model is trained. Finn solves this by leveraging the [tune](https://tune.tidymodels.org/reference/tune.html) package within the tidymodels ecosystem.

When `prep_models()` is ran, hyperparameters and back test splits are calculated and written to disk. You can get the results by calling `get_prepped_models()`.

```{r, echo = FALSE, message = TRUE}
library(finnts)

hist_data <- timetk::m4_monthly %>%
  dplyr::filter(date >= "2010-01-01", 
                id == "M2") %>%
  dplyr::rename(Date = date) %>%
  dplyr::mutate(id = as.character(id))

run_info <- set_run_info(
  experiment_name = "finnts_fcst", 
  run_name = "get_prepped_models"
)

prep_data(run_info = run_info, 
          input_data = hist_data, 
          combo_variables = c("id"), 
          target_variable = "value", 
          date_type = "month", 
          forecast_horizon = 6)

prep_models(run_info = run_info, 
            models_to_run = c("arima", "ets", "xgboost"), 
            num_hyperparameters = 10)

model_info <- get_prepped_models(run_info = run_info)

back_test_info <- model_info %>%
  dplyr::filter(Type == "Train_Test_Splits") %>%
  dplyr::select(Data) %>%
  tidyr::unnest(Data)

print(back_test_info)
print(unique(back_test_info$Run_Type))

model_workflow_info <- model_info %>%
  dplyr::filter(Type == "Model_Workflows") %>%
  dplyr::select(Data) %>%
  tidyr::unnest(Data)

print(model_workflow_info)

model_hyperparameter_info <- model_info %>%
  dplyr::filter(Type == "Model_Hyperparameters") %>%
  dplyr::select(Data) %>%
  tidyr::unnest(Data)

print(model_hyperparameter_info)

```

The above outputs allow a Finn user to understand what hyperparameters are chosen for tuning and how the model refitting process will work. When tuning hyperparameters, Finn uses the "Validation" train/test splits, with the final parameters chosen using RMSE. For some models like ARIMA that don't follow a traditional hyperparameter tuning process, the model is fit from scratch across all train/test splits. After hyperparameters are chosen, the model is refit across the "Back_Test" and "Future_Forecast" splits. The "Back_Test" splits are the true testing data that will be used when selecting the final "Best-Model". "Ensemble" splits are also created as ensemble training data if ensemble models are chosen to run. Ensemble models follow a similar tuning process.
